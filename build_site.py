import json
import os
import datetime
import shutil
import random
import re

# --- é…ç½® ---
DATA_FILE = 'symbols_updated.json'     # æ•°æ®æº
TEMPLATE_FILE = 'symbol_template.html' # æ¨¡æ¿æ–‡ä»¶
OUTPUT_DIR = 'public'
DREAMS_DIR = os.path.join(OUTPUT_DIR, 'dreams')
DOMAIN = "https://dreamwhisperai.com" # !!! è¯·æ›¿æ¢ä¸ºä½ çš„çœŸå®åŸŸå !!!

# --- SEO æ´—ç¨¿æ–‡æ¡ˆåº“ ---
SEO_TITLES_ZH = [
    "æ¢¦è§{name}æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ2025å¹´å¿ƒç†å­¦ä¸å‘¨å…¬è§£æ¢¦å…¨è§£æ",
    "æ˜¨æ™šæ¢¦è§{name}ï¼Ÿæ­ç§˜æ½œæ„è¯†ç»™ä½ çš„3ä¸ªæš—ç¤º",
    "ã€è§£æ¢¦ç™¾ç§‘ã€‘æ¢¦è§{name}æ˜¯å‰æ˜¯å‡¶ï¼Ÿå®Œæ•´ç‰ˆè§£ææ¥äº†",
    "æ¢¦è§{name}é¢„ç¤ºç€ä»€ä¹ˆï¼Ÿä¸“å®¶è§£è¯»æ¢¦å¢ƒèƒŒåçš„ç§˜å¯†",
    "åšæ¢¦æ¢¦åˆ°{name}ï¼Ÿè¿™ç¯‡åˆ†æå¯èƒ½é¢ è¦†ä½ çš„è®¤çŸ¥",
    "å‘¨å…¬è§£æ¢¦ï¼šæ¢¦è§{name}çš„å¯“æ„ä¸è¿åŠ¿æé†’",
    "å¿ƒç†å­¦è§£è¯»ï¼šä¸ºä»€ä¹ˆä½ ä¼šæ¢¦è§{name}ï¼Ÿ"
]

INTRO_TEMPLATES_ZH = [
    "æ¢¦å¢ƒæ˜¯æ½œæ„è¯†çš„è¯­è¨€ã€‚æ¢¦è§<strong>{name}</strong>ç©¶ç«Ÿæ„å‘³ç€ä»€ä¹ˆï¼Ÿ",
    "ä½ æ˜¯å¦æ˜¨æ™šæ¢¦è§äº†<strong>{name}</strong>ï¼Ÿè¿™å¯èƒ½ä¸æ˜¯ä¸€ä¸ªå·§åˆã€‚",
    "åœ¨ä¸­å›½ä¼ ç»Ÿæ–‡åŒ–ä¸­ï¼Œ<strong>{name}</strong>å¾€å¾€æ‰¿è½½ç€ç‰¹æ®Šçš„è±¡å¾æ„ä¹‰ã€‚",
    "å½“ä½ é†’æ¥è®°å¾—è‡ªå·±æ¢¦è§äº†<strong>{name}</strong>ï¼Œä½ çš„æ½œæ„è¯†æ­£åœ¨è¯•å›¾å‘Šè¯‰ä½ ä»€ä¹ˆï¼Ÿ",
    "<strong>{name}</strong>å‡ºç°åœ¨æ¢¦ä¸­ï¼Œé€šå¸¸ä¸ä½ è¿‘æœŸçš„æƒ…ç»ªçŠ¶æ€æ¯æ¯ç›¸å…³ã€‚"
]

# --- è¾…åŠ©å‡½æ•°ï¼šæ¸…ç† HTML æ ‡ç­¾ç”¨äº Meta æ ‡ç­¾ ---
def clean_html_tags(text):
    if not text: return ""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text).replace('"', "'").replace('\n', ' ')

# --- ç¡®ä¿ç›®å½•å­˜åœ¨ ---
if not os.path.exists(DREAMS_DIR):
    os.makedirs(DREAMS_DIR)

def load_data():
    if not os.path.exists(DATA_FILE):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ° {DATA_FILE}ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™« scraper.py")
        return []
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def build_detail_pages(data):
    print(f"æ­£åœ¨åŠ è½½æ¨¡æ¿: {TEMPLATE_FILE}...")
    try:
        with open(TEMPLATE_FILE, 'r', encoding='utf-8') as f:
            template_content = f.read()
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡æ¿æ–‡ä»¶ {TEMPLATE_FILE}")
        return

    count = 0
    for item in data:
        html = template_content
        zh_data = item.get('zh', {})
        name = zh_data.get('name', '')
        
        # --- 1. å†…å®¹ç”Ÿæˆ ---
        seo_title_template = random.choice(SEO_TITLES_ZH)
        seo_title = seo_title_template.format(name=name)
        
        intro_template = random.choice(INTRO_TEMPLATES_ZH)
        seo_intro = intro_template.format(name=name)
        
        original_summary = zh_data.get('summary', '')
        # é¡µé¢æ˜¾ç¤ºç”¨çš„æ‘˜è¦ï¼ˆä¿ç•™HTMLæ ‡ç­¾ï¼‰
        final_summary_html = f"{seo_intro}<br/><br/>{original_summary}"
        
        # Meta æ ‡ç­¾ç”¨çš„çº¯æ–‡æœ¬æ‘˜è¦
        meta_description = clean_html_tags(f"{seo_intro} {original_summary}")[:160] + "..."

        # --- 2. æ„é€  SEO å¤´éƒ¨æ ‡ç­¾ (SEO Injection) ---
        filename = item.get('filename', f"symbol-{count}.html")
        full_url = f"{DOMAIN}/dreams/{filename}"
        
        seo_tags = f"""
    <!-- Auto-Injected SEO Tags -->
    <meta name="description" content="{meta_description}">
    <meta name="keywords" content="æ¢¦è§{name}, {name}è§£æ¢¦, {name}è±¡å¾æ„ä¹‰, å‘¨å…¬è§£æ¢¦{name}, å¿ƒç†å­¦è§£æ¢¦">
    <link rel="canonical" href="{full_url}">
    <meta property="og:title" content="{seo_title}">
    <meta property="og:description" content="{meta_description}">
    <meta property="og:url" content="{full_url}">
    <meta property="og:type" content="article">
    
    <!-- JSON-LD Structured Data -->
    <script type="application/ld+json">
    {{
      "@context": "https://schema.org",
      "@type": "Article",
      "headline": "{seo_title}",
      "description": "{meta_description}",
      "mainEntityOfPage": {{
        "@type": "WebPage",
        "@id": "{full_url}"
      }},
      "author": {{
        "@type": "Organization",
        "name": "DreamWhisper"
      }}
    }}
    </script>
        """

        # --- 3. æ‰§è¡Œæ›¿æ¢ ---
        
        # 3.1 æ³¨å…¥ SEO æ ‡ç­¾åˆ° </head> ä¹‹å‰
        if '</head>' in html:
            html = html.replace('</head>', f"{seo_tags}\n</head>")
        
        # 3.2 æ›¿æ¢ Title
        if '<title>' in html:
            target_str = "è±¡å¾å­—å…¸ - {{ZH_NAME}} ({{EN_NAME}})"
            if target_str in html:
                html = html.replace(target_str, seo_title)
            else:
                html = html.replace('<title>', f'<title>{seo_title} | ')
        
        # 3.3 æ›¿æ¢æ­£æ–‡å†…å®¹
        html = html.replace('{{ZH_NAME}}', name)
        html = html.replace('{{ZH_SUBNAME}}', zh_data.get('subname', ''))
        html = html.replace('{{ZH_SUMMARY}}', final_summary_html) # æ³¨æ„è¿™é‡Œç”¨å¸¦HTMLçš„
        html = html.replace('{{ZH_PSYCH_1}}', zh_data.get('psych_1', ''))
        html = html.replace('{{ZH_PSYCH_2}}', zh_data.get('psych_2', ''))
        html = html.replace('{{ZH_TRAD_GOOD}}', zh_data.get('trad_good', ''))
        html = html.replace('{{ZH_TRAD_BAD}}', zh_data.get('trad_bad', ''))
        
        # 3.4 æ•°æ®æ³¨å…¥
        json_str = json.dumps(item, ensure_ascii=False)
        html = html.replace('"REPLACE_ME_WITH_JSON"', json_str)
        html = html.replace("'REPLACE_ME_WITH_JSON'", json_str)

        # --- 4. å†™å…¥æ–‡ä»¶ ---
        path = os.path.join(DREAMS_DIR, filename)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(html)
        count += 1

    print(f"æˆåŠŸç”Ÿæˆ {count} ä¸ªè¯¦æƒ…é¡µé¢ (SEOå…¨é‡å¢å¼ºç‰ˆ) åˆ° {DREAMS_DIR}")

def generate_index_page(data):
    sorted_data = sorted(data, key=lambda x: len(x['zh']['name']))
    links_html = ""
    for item in sorted_data:
        name = item['zh']['name']
        filename = item['filename']
        links_html += f'<li><a href="dreams/{filename}">{name}</a></li>'

    html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è§£æ¢¦ç™¾ç§‘å…¨ä¹¦ - ç´¢å¼•</title>
    <meta name="description" content="DreamWhisper è§£æ¢¦ç™¾ç§‘å…¨ä¹¦ï¼Œæ”¶å½•è¶…è¿‡ {len(data)} ä¸ªå¸¸è§æ¢¦å¢ƒæ„è±¡çš„å¿ƒç†å­¦è§£æä¸ä¼ ç»Ÿå‘¨å…¬è§£æ¢¦å¯¹ç…§ã€‚">
    <style>
        body {{ font-family: -apple-system, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; background: #f5f7fa; }}
        h1 {{ text-align: center; color: #2c3e50; }}
        .search-box {{ text-align: center; margin-bottom: 30px; }}
        input {{ padding: 10px 20px; width: 80%; max-width: 400px; border-radius: 20px; border: 1px solid #ddd; font-size: 16px; }}
        ul {{ list-style: none; padding: 0; display: flex; flex-wrap: wrap; gap: 10px; justify-content: center; }}
        li a {{ display: block; padding: 10px 20px; background: white; text-decoration: none; color: #333; border-radius: 8px; transition: 0.2s; box-shadow: 0 2px 5px rgba(0,0,0,0.05); }}
        li a:hover {{ background: #3498db; color: white; transform: translateY(-2px); }}
    </style>
</head>
<body>
    <h1>ğŸ˜´ è§£æ¢¦ç™¾ç§‘ç´¢å¼• ({len(data)})</h1>
    <div class="search-box">
        <input type="text" id="search" placeholder="æœç´¢å…³é”®è¯..." onkeyup="filter()">
    </div>
    <ul id="list">
        {links_html}
    </ul>
    <script>
        function filter() {{
            var input = document.getElementById('search');
            var filter = input.value.toUpperCase();
            var ul = document.getElementById("list");
            var li = ul.getElementsByTagName('li');
            for (var i = 0; i < li.length; i++) {{
                var a = li[i].getElementsByTagName("a")[0];
                if (a.innerHTML.toUpperCase().indexOf(filter) > -1) {{
                    li[i].style.display = "";
                }} else {{
                    li[i].style.display = "none";
                }}
            }}
        }}
    </script>
</body>
</html>"""
    
    with open(os.path.join(OUTPUT_DIR, 'index.html'), 'w', encoding='utf-8') as f:
        f.write(html)
    print(f"ç´¢å¼•é¡µå·²ç”Ÿæˆ: {os.path.join(OUTPUT_DIR, 'index.html')}")

def generate_sitemap(data):
    sitemap_content = '<?xml version="1.0" encoding="UTF-8"?>\n'
    sitemap_content += '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    today = datetime.date.today().isoformat()
    sitemap_content += f"  <url><loc>{DOMAIN}/index.html</loc><lastmod>{today}</lastmod></url>\n"
    for item in data:
        sitemap_content += f"  <url><loc>{DOMAIN}/dreams/{item['filename']}</loc><priority>0.8</priority></url>\n"
    sitemap_content += '</urlset>'
    with open(os.path.join(OUTPUT_DIR, 'sitemap.xml'), 'w', encoding='utf-8') as f:
        f.write(sitemap_content)
    print(f"Sitemap å·²ç”Ÿæˆ")

def main():
    print("=== å¼€å§‹æ„å»ºç½‘ç«™ (Final SEO Version) ===")
    data = load_data()
    if not data: return

    # æ¸…ç†æ—§ç›®å½•
    en_dir = os.path.join(OUTPUT_DIR, 'en')
    if os.path.exists(en_dir):
        shutil.rmtree(en_dir)

    build_detail_pages(data)
    generate_index_page(data)
    generate_sitemap(data)
    print("\n=== æ„å»ºå®Œæˆï¼ç°åœ¨å¯ä»¥å¼€å§‹æµ‹è¯•äº†ã€‚ ===")
    print("è®°å¾—æ£€æŸ¥ HTML æºä»£ç ä¸­çš„ <meta> æ ‡ç­¾å’Œ JSON-LD æ•°æ®ã€‚")

if __name__ == "__main__":
    main()